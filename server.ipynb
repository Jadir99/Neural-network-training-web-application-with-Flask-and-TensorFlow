{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,177</span> (8.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,177\u001b[0m (8.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,177</span> (8.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,177\u001b[0m (8.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def dynamic_import(module_name, class_name):\n",
    "    # Dynamically import the module\n",
    "    module = importlib.import_module(module_name)\n",
    "    # Get the class or object from the module\n",
    "    return getattr(module, class_name)\n",
    "\n",
    "# Dynamically import Sequential from tensorflow.keras.models\n",
    "Sequential = dynamic_import('tensorflow.keras.models', 'Sequential')\n",
    "\n",
    "# Dynamically import Dense from tensorflow.keras.layers\n",
    "Dense = dynamic_import('tensorflow.keras.layers', 'Dense')\n",
    "\n",
    "# Example usage of Sequential and Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def load_data():\n",
    "    X = np.load(\"static/uploads/data/X.npy\")\n",
    "    y = np.load(\"static/uploads/data/y.npy\")\n",
    "    X = X[0:1000]\n",
    "    y = y[0:1000]\n",
    "    \n",
    "    return X, y\n",
    "def load_weights():\n",
    "    W1,b1 = np.load('weights/w1.npy'), np.load('weights/b1.npy')\n",
    "    W2,b2 = np.load('weights/w2.npy'), np.load('weights/b2.npy')\n",
    "    W3,b3 = np.load('weights/w3.npy'), np.load('weights/b3.npy')\n",
    "    return W1,b1,W2,b2,W3,b3\n",
    "\n",
    "\n",
    "def plot_data(X,y):\n",
    "    m, n = X.shape\n",
    "    fig, axes = plt.subplots(4,4, figsize=(4,4))\n",
    "    fig.tight_layout(pad=0.1)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Sélectionner des indices aléatoires\n",
    "        random_index =  np.random.randint(0,m)\n",
    "        \n",
    "        # Sélectionner les lignes correspondant aux indices aléatoires et\n",
    "        # redimensionner l'image\n",
    "        X_random_reshaped =  X[random_index].reshape(20,20)\n",
    "        \n",
    "        # Afficher l'image\n",
    "        ax.imshow(X_random_reshaped)\n",
    "        \n",
    "        # Afficher l'étiquette au-dessus de l'image\n",
    "        ax.set_title(y[random_index, 0])\n",
    "        ax.set_axis_off()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    # df=pd.read_csv('static/uploads/champs.csv')\n",
    "    # plt.plot(df['name'])\n",
    "    X,y=load_data()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    #plotthe data before trainng\n",
    "    plot_data(X_train,y_train)\n",
    "    \n",
    "    return X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implimentation using tensorflow\n",
    "def train_tensorflow(activation,X,units):\n",
    "\n",
    "    model = Sequential(\n",
    "        [               \n",
    "            tf.keras.Input(shape=(X.shape[1],)),    #La taille d'entrée\n",
    "            # Votre code ici -----------------------------------\n",
    "            Dense(units=25,activation=activation),\n",
    "            Dense(units=15,activation=activation),\n",
    "            Dense(units=1,activation=activation),\n",
    "            # Votre code ici -----------------------------------\n",
    "        ], name = \"my_model\" \n",
    "    )  \n",
    "    print(model.summary())\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Prototype for training function with Pandas DataFrame\n",
    "def train_tensor(nbr_layers, nbr_neurals, activation, alpha, loss, optimizer, epoches, data, target_column):\n",
    "    \"\"\"\n",
    "    nbr_layers: Number of layers (int)\n",
    "    nbr_neurons: Number of neurons per layer (list of ints) \n",
    "    activation: Activation function per layer (list of strings, e.g., 'relu', 'sigmoid')\n",
    "    alpha: Learning rate (float)\n",
    "    loss: Loss function (string, e.g., 'mean_squared_error')\n",
    "    optimizer: Optimizer function (string, e.g., 'adam')\n",
    "    epochs: Number of epochs (int)\n",
    "    data: Pandas DataFrame (data) containing features and target column\n",
    "    target_column: Name of the target column for regression (string)\n",
    "    \"\"\"\n",
    "    # Split the DataFrame into features (X) and target (y)\n",
    "    X = data.drop(columns=[target_column])  # All columns except the target column\n",
    "    y = data[target_column]  # Target column for prediction\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    # Build the model\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Add input layer with the number of features (columns) in X\n",
    "    model.add(layers.InputLayer(input_shape=(X_train.shape[1],)))\n",
    "    \n",
    "    # Add hidden layers\n",
    "    for i in range(nbr_layers):\n",
    "        model.add(layers.Dense(units=nbr_neurals[i], activation=activation[i]))\n",
    "    \n",
    "    # Add final layer for regression (output a single value)\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    # Compile the model with the given optimizer and learning rate\n",
    "    optimizer_func = getattr(tf.keras.optimizers, optimizer)(learning_rate=alpha)\n",
    "    model.compile(loss=loss, optimizer=optimizer_func)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=epoches, batch_size=32, validation_split=0.2)\n",
    "    \n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - loss: 145783.5000 - val_loss: 1.9354\n",
      "Epoch 2/10\n",
      "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 89.9668 - val_loss: 43.5097\n",
      "Epoch 3/10\n",
      "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 481.1045 - val_loss: 0.7906\n",
      "Epoch 4/10\n",
      "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 74.9514 - val_loss: 0.0176\n",
      "Epoch 5/10\n",
      "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 2.4330 - val_loss: 160.1642\n",
      "Epoch 6/10\n",
      "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 827.2957 - val_loss: 7.3347\n",
      "Epoch 7/10\n",
      "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 971us/step - loss: 39.3917 - val_loss: 0.0053\n",
      "Epoch 8/10\n",
      "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 4.6899 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - loss: 0.0073 - val_loss: 0.0024\n",
      "Epoch 10/10\n",
      "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 2.6458 - val_loss: 0.0017\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a CSV file and load it into a Pandas DataFrame\n",
    "data = pd.read_csv('C:/Users/moham/OneDrive/Bureau/detec_fraud/creditcard.csv')\n",
    "\n",
    "# Define your parameters for the model\n",
    "nbr_layers = 3\n",
    "nbr_neurals = [64, 32, 16]\n",
    "activation = ['relu', 'relu', 'relu']\n",
    "alpha = 0.001\n",
    "loss = 'mean_squared_error'\n",
    "optimizer = 'Adam'\n",
    "epoches = 10\n",
    "\n",
    "# Call the function, passing the DataFrame and target column name\n",
    "model, history = train_tensor(nbr_layers, nbr_neurals, activation, alpha, loss, optimizer, epoches, data, 'Class')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model.save('my_model.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Downloading boto3-1.35.42-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting botocore<1.36.0,>=1.35.42 (from boto3)\n",
      "  Downloading botocore-1.35.42-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
      "  Downloading s3transfer-0.10.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\moham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from botocore<1.36.0,>=1.35.42->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\moham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from botocore<1.36.0,>=1.35.42->boto3) (2.2.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.42->boto3) (1.16.0)\n",
      "Downloading boto3-1.35.42-py3-none-any.whl (139 kB)\n",
      "Downloading botocore-1.35.42-py3-none-any.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"C:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 561, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 527, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 98, in read\n",
      "    data: bytes = self.__fp.read(amt)\n",
      "                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py\", line 479, in read\n",
      "    s = self.fp.read(amt)\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 105, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 96, in _inner_run\n",
      "    return self.run(options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 379, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "                      ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 179, in resolve\n",
      "    self.factory.preparer.prepare_linked_requirements_more(reqs)\n",
      "  File \"C:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 554, in prepare_linked_requirements_more\n",
      "    self._complete_partial_requirements(\n",
      "  File \"C:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 469, in _complete_partial_requirements\n",
      "    for link, (filepath, _) in batch_download:\n",
      "  File \"C:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_internal\\network\\download.py\", line 184, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"C:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 55, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"C:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 65, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"C:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 622, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 560, in read\n",
      "    with self._error_catcher():\n",
      "  File \"C:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"C:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'boto3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mboto3\u001b[39;00m\n\u001b[0;32m      3\u001b[0m s3 \u001b[38;5;241m=\u001b[39m boto3\u001b[38;5;241m.\u001b[39mclient(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m s3\u001b[38;5;241m.\u001b[39mupload_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maza.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmy-bucket-name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmy_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'boto3'"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "s3.upload_file('aza.h5', 'my-bucket-name', 'my_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "\n",
    "gdown.download('YOUR_GOOGLE_DRIVE_LINK', 'my_model.h5', quiet=False)\n",
    "model = load_model('my_model.h5')\n",
    "s3.download_file('my-bucket-name', 'my_model.h5', 'my_model.h5')\n",
    "model = load_model('my_model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
